{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOlVhbzwGeIIYBgeiRymE+I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavbajpai79/AIML/blob/main/CV_N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqB6aO99FBnJ",
        "outputId": "60e613ca-936f-470d-8dd5-b0f5b2be4291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/darren2020/ct-to-mri-cgan\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "ct-to-mri-cgan.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  ct-to-mri-cgan.zip\n",
            "replace data/Dataset/images/testA/ct10.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Step 1: Download and Unzip the Dataset (From the provided notebook cell)\n",
        "#   This part downloads and extracts the data.  It should be placed at the VERY beginning\n",
        "#   of your notebook to ensure the data is available.\n",
        "\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d darren2020/ct-to-mri-cgan\n",
        "!unzip ct-to-mri-cgan.zip -d data/\n",
        "\n",
        "# Step 2: Define Dataset Paths (Aligned with the data structure)\n",
        "CT_DIR = \"data/Dataset/images/trainA/\"\n",
        "MRI_DIR = \"data/Dataset/images/trainB/\" # This path is defined, but MRI data is not used in OCSVM\n",
        "\n",
        "# Step 3: Define CTMRIDataset and DataLoader (Using PyTorch)\n",
        "class CTMRIDataset(Dataset):\n",
        "    def __init__(self, ct_dir, transform=None): #Simplified: Only CT needed for OCSVM\n",
        "        self.ct_images = sorted([os.path.join(ct_dir, f) for f in os.listdir(ct_dir) if f.endswith('.png')])\n",
        "        self.transform = transform\n",
        "        print(f\"Number of CT images: {len(self.ct_images)}\") # Print length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ct_images) #Simplified: only depends on CT\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ct_img = cv2.imread(self.ct_images[idx], cv2.IMREAD_GRAYSCALE) # Read CT image\n",
        "        ct_img = Image.fromarray(ct_img) # Convert to PIL Image\n",
        "\n",
        "        if self.transform:\n",
        "            ct_img = self.transform(ct_img)\n",
        "\n",
        "        return ct_img #Return only the CT image\n",
        "\n",
        "# Define transformations (Resizing, Normalization, and conversion to NumPy array)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = CTMRIDataset(CT_DIR, transform=transform)\n",
        "train_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Step 4: Feature Extraction using CNN (Using PyTorch)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 56 * 56, 128) #Adjust the input size\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the CNN\n",
        "cnn = SimpleCNN()\n",
        "\n",
        "# Check if CUDA is available and use it if possible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "cnn.to(device) # Move the CNN to the GPU if available\n",
        "\n",
        "def extract_features(dataloader, model, device):\n",
        "    features = []\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        for batch in dataloader:\n",
        "            batch = batch.to(device)  # Move to device directly, no need to unsqueeze\n",
        "            output = model(batch)\n",
        "            features.append(output.cpu().numpy())  # Move to CPU and convert to NumPy array\n",
        "    return np.concatenate(features, axis=0)\n",
        "\n",
        "# Extract training features\n",
        "train_features = extract_features(train_loader, cnn, device)\n",
        "\n",
        "# Step 5: Data Scaling\n",
        "scaler = StandardScaler()\n",
        "train_features_scaled = scaler.fit_transform(train_features)\n",
        "\n",
        "# Step 6: One-Class SVM Training\n",
        "ocsvm = OneClassSVM(kernel='rbf', nu=0.01)  # Adjust nu as needed\n",
        "ocsvm.fit(train_features_scaled)\n",
        "\n",
        "# Step 7: Load Anomaly Data and Extract Features for Testing\n",
        "# In practice, you would load anomaly data (e.g., from another directory)\n",
        "# and extract features from it using the SAME CNN and scaling.\n",
        "# For demonstration, let's create some dummy anomaly data by adding noise.\n",
        "# This is just for example: replace this with real anomaly data!\n",
        "\n",
        "# Step 7a: Create Dummy Anomaly Data\n",
        "def create_dummy_anomaly_data(normal_data, num_anomalies, noise_level=0.2):\n",
        "    num_samples, img_height, img_width = normal_data.shape[0], normal_data[0].shape[1], normal_data[0].shape[2]\n",
        "    anomaly_indices = np.random.choice(num_samples, num_anomalies, replace=False)\n",
        "    anomaly_data = normal_data[anomaly_indices].copy()\n",
        "    noise = np.random.normal(0, noise_level, anomaly_data.shape)\n",
        "    anomaly_data = np.clip(anomaly_data + noise, -1, 1)  # Clip values to be within [-1, 1]\n",
        "    return anomaly_data, anomaly_indices\n",
        "\n",
        "#Number of anomalies, adjust this\n",
        "num_anomalies = 50\n",
        "dummy_anomalies, anomaly_indices = create_dummy_anomaly_data(normal_ct_images, num_anomalies)\n",
        "\n",
        "# Create test dataset with normal and anomalies\n",
        "test_data = np.concatenate([normal_ct_images, dummy_anomalies])\n",
        "\n",
        "#Create labels (1 for normal, -1 for anomaly)\n",
        "test_labels = np.concatenate([np.ones(len(normal_ct_images)), -np.ones(len(dummy_anomalies))])\n",
        "np.random.shuffle(test_labels) #shuffle labels\n",
        "\n",
        "#Create a test dataloader to feed into feature extraction\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        image = Image.fromarray((image*255).astype(np.uint8).squeeze()) #Convert back to PIL Image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Create a combined test dataset and dataloader\n",
        "test_dataset = TestDataset(test_data, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False) #No need to shuffle test data\n",
        "\n",
        "# Step 7b: Extract Test Features\n",
        "test_features = extract_features(test_loader, cnn, device)\n",
        "\n",
        "# Step 8: Data Scaling for test features\n",
        "test_features_scaled = scaler.transform(test_features)\n",
        "\n",
        "# Step 9: Anomaly Scoring with One-Class SVM\n",
        "ocsvm_scores = ocsvm.decision_function(test_features_scaled)\n",
        "\n",
        "# Step 10: Evaluation using AUC-ROC\n",
        "auc = roc_auc_score(test_labels, ocsvm_scores)\n",
        "print(f\"AUC-ROC: {auc}\")\n",
        "\n",
        "# Step 11: Visualize ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(test_labels, ocsvm_scores)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, label=f'One-Class SVM (AUC = {auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ]
}